.. _architecture:

##########################
系统架构设计
##########################

本文档详细描述了 Qzen 项目的技术选型、系统架构和关键设计决策。

推荐技术栈
======================

.. list-table:: 技术栈详情
   :widths: 20 20 20 40
   :header-rows: 1

   * - 组件分类
     - 技术选型
     - 建议版本
     - 选型理由
   * - GUI框架
     - PyQt6
     - 6.5+
     - 功能强大、成熟稳定，通过 ``QThread`` 能完美解决UI响应性问题。
   * - 数据持久化/ORM
     - SQLAlchemy
     - 2.0+
     - 将业务逻辑与DM8数据库解耦，代码更清晰，易于维护。
   * - 中文分词
     - Jieba
     - 0.42+
     - 社区广泛使用，分词效果好，支持自定义词典和停用词，满足项目需求。
   * - 相似度计算
     - Scikit-learn
     - 1.3+
     - 提供工业级的TF-IDF和余弦相似度算法，满足“简约高效”的要求。
   * - 近邻搜索加速
     - Scikit-learn
     - 1.3+
     - 内置的 ``NearestNeighbors`` 类足以在5000个文档的规模下实现快速搜索。
   * - 应用打包
     - PyInstaller
     - 6.0+
     - 将项目打包为单个 ``.exe`` 文件，便于Windows用户分发和使用。
   * - 文档生成
     - Sphinx
     - 7.0+
     - 遵循DDAC工作流，实现代码与文档的同步。

graphviz_output_format = 'png'

graphviz_dot_args = [ '-Gcharset=utf8'  # <-- 强制 Graphviz 使用 UTF-8 编码处理文本 ]

系统架构
================

本项目采用 **三层分层架构 (3-Tier Architecture)**，将系统解耦为表现层、业务逻辑层和数据访问层。

.. graphviz::
   :align: center

   digraph Architecture {
      // --- 全局字体和编码设置 ---
      graph [fontname="Microsoft YaHei"];
      node  [fontname="Microsoft YaHei"];
      edge  [fontname="Microsoft YaHei"];

      // --- 布局和样式设置 ---
      rankdir=TB;
      node [shape=box, style=rounded];

      // --- 图形内容 ---
      subgraph cluster_ui {
         label = "表现层 (Presentation Layer)";
         ui [label="用户界面 (PyQt6)\n接收用户操作，展示部分结果"];
      }

      subgraph cluster_core {
         label = "业务逻辑层 (Business Logic Layer)";
         core [label="核心功能模块\n去重、相似度计算、聚类"];
      }

      subgraph cluster_data {
         label = "数据访问层 (Data Access Layer)";
         dal [label="数据访问接口 (SQLAlchemy, os)"];
      }

      subgraph cluster_datasource {
         label = "数据源 (Data Sources)";
         filesystem [label="文件系统"];
         database [label="DM8 数据库"];
      }

      ui -> core [label="调用功能接口 / 请求取消"];
      core -> ui [label="返回 (总结, 结果子集) / 状态"];
      core -> dal [label="请求/写入数据"];
      dal -> core [label="返回数据"];
      dal -> filesystem;
      dal -> database [label="读/写 全部结果与缓存"];
   }

* **表现层 (UI)**: 完全由 ``qzen_ui`` 包负责。它包含所有的窗口、控件和事件处理逻辑，并通过调用业务逻辑层的接口来响应用户交互。
* **业务逻辑层 (Core)**: 由 ``qzen_core`` 包负责。它实现了所有核心算法和业务规则，不依赖于任何UI或具体的数据库实现。
* **数据访问层 (DAL)**: 由 ``qzen_data`` 包负责。它抽象了所有对文件系统和DM8数据库的访问，为上层提供统一、简洁的数据操作接口。

关键设计决策
====================

1.  **UI响应性**: 所有耗时操作（文件扫描、数据库查询、相似度计算） **必须** 在后台线程 (``QThread``) 中执行。主UI线程仅负责更新界面和与用户交互，从而确保界面在处理大量文件时依然流畅。

2.  **协作式任务取消**: 为了在长时间运行的任务中给予用户控制权，我们实现了一个协作式的取消机制。用户可以随时请求中止正在进行的操作，而程序会安全、优雅地退出任务。
    * **设计原则**: 我们不采用强制终止线程的“抢占式”方法，因为它可能导致资源不被释放或数据状态不一致。取而代之的是“协作式”模型，即后台任务在执行过程中的关键节点（如循环的每次迭代）会主动检查是否收到了取消请求。
    * **工作流程**: 
        1. 用户在UI上点击“取消”按钮。
        2. UI线程调用后台 `Worker` 线程的 `cancel()` 方法。
        3. `Worker` 线程设置一个内部的“已请求取消”标志位。
        4. `Orchestrator` 中的核心业务逻辑在循环处理数据的过程中，会频繁检查这个标志位。
        5. 一旦检测到取消请求，业务逻辑会立即停止处理新数据，放弃当前任务，并返回一个“任务已取消”的状态。

3.  **轻量级相似度算法**: 我们选择 **TF-IDF + 余弦相似度** 而非深度学习模型（如BERT）。这个决策基于以下考虑：
    * **性能**: 对于数千级别的文档，该方法计算速度快，资源消耗低，完全满足性能要求。
    * **简单性**: 算法成熟，易于实现和调试。
    * **效果**: 对于文档聚类和相似性排序任务，该方法已经能提供足够好的、可接受的近似结果。

4.  **数据库作为核心存储**: DM8数据库是系统的核心存储引擎，它扮演双重角色：
    * **缓存和索引**: 存储文档的哈希值、内容切片、特征向量等中间计算结果。下次运行时，程序会先检查数据库，避免重复计算，从而极大地加速了处理过程。
    * **结果持久化**: 存储所有操作的最终结果，如去重列表、重命名映射和搜索结果。这取代了之前将大量结果返回到内存的做法。

5.  **混合式结果处理策略**: 这是一个关键的架构决策，旨在同时满足大规模数据处理的健壮性和小规模数据下的即时用户反馈。其工作流程如下：
    * **全部结果持久化**: 业务逻辑层执行的所有任务（去重、重命名、搜索等）的 **全部结果** 都将被逐条或批量写入数据库中的专用表格。这确保了数据的完整性、可追溯性，并避免了内存瓶颈。
    * **部分结果反馈至UI**: 在将全部结果存入数据库后，业务逻辑层会返回一个 **结果集的子集（最多100条）** 给UI层。这使得用户可以立即看到操作的直观反馈，而无需打开数据库客户端。
    * **UI层职责**: UI层负责接收并展示这个结果子集。如果结果总数超过100条，UI需要明确告知用户这只是部分结果，完整结果已存入数据库。

6.  **用户可配置的算法参数**: 为了在易用性和灵活性之间取得平衡，我们将部分核心算法的关键参数暴露给用户，允许高级用户根据其具体需求进行调优。同时，为了避免给普通用户带来困扰，我们采用 **UI内联帮助** 的方式进行引导。
    * **设计原则**: 不将所有参数都暴露出来，仅选择对性能和结果质量有显著影响、且用户能够理解的参数。
    * **UI实现**: 在配置界面，每个参数设置控件旁边都会附有一个帮助图标。当用户鼠标悬停在此图标上时，会显示一个工具提示（Tooltip），用平实的语言解释该参数的含义、默认值、以及调整它可能带来的影响。
    * **首批可配置参数**:
        * **TF-IDF 最大特征数 (`max_features`)**: 控制用于文本分析的词汇表大小。增加此值可以提高对特定领域文档的分析精度，但会消耗更多内存和计算时间。
        * **内容切片大小 (`slice_size_kb`)**: 为计算文档相似度而提取的文档首尾部分的大小。增加此值可以更准确地代表长文档，但同样会增加内存和计算开销。

7.  **交互式结果呈现**: 为了将Qzen从一个分析工具转变为一个高效的整理工具，UI中显示的结果列表将不再是静态的。用户可以直接与结果进行交互。
    * **实现机制**: 为所有结果列表和表格（去重、重命名、搜索等）添加右键上下文菜单。
    * **核心操作**: 当用户右键点击一个结果项时，将弹出一个菜单，提供以下核心操作：
        * **打开文件所在目录**: 使用系统文件管理器打开包含该文件的文件夹，方便用户快速定位和处理文件。
        * **复制文件路径**: 将所选文件的完整路径复制到系统剪贴板，便于在其他程序中使用。
    * **价值**: 这一改进将分析（“我发现了这些重复文件”）与操作（“我现在就去处理它们”）无缝连接起来，极大地提升了用户的工作效率。

8.  **面向接口而非实现编程**: 各层之间的交互应通过定义好的接口（例如，业务层的一个类和方法）进行。这使得我们可以轻松地对某一层进行单元测试（例如，使用模拟数据测试业务逻辑层）或在未来进行技术升级。

9.  **中文文本预处理流程 (Chinese Text Preprocessing Pipeline)**: 为了从根本上提升相似度计算的准确性，我们必须在将文本送入 TF-IDF 向量化器之前，实施一个健壮的预处理流程。原始的、未经处理的文本切片包含大量噪声（如标点、特殊字符、多余的空格和换行），并且对于中文等多字节语言，默认的基于空格的分词方法完全无效。因此，我们引入一个标准化的三步预处理流程，该流程将应用于所有文档的内容切片。

    * **设计原则**: 该流程旨在将非结构化的原始文本转化为干净、标准化的词语序列，为后续的机器学习模型提供高质量的输入。

    * **工作流程**:
        1.  **文本清洗 (Text Cleaning)**: 这是预处理的第一步。我们将使用正则表达式 (regex) 来清除所有非必要的字符。
            *   移除所有中英文标点符号、数字和特殊字符。
            *   将所有连续的空白字符（包括空格、换行符 `\n`、制表符 `\t`）替换为单个空格。
            *   移除可能存在的乱码或不可见字符。
            *   此步骤将在 ``qzen_data.file_handler`` 模块中实现，确保从文件提取内容后立即进行清洗。

        2.  **中文分词 (Chinese Word Segmentation)**: 由于中文词语之间没有天然的分隔符，必须使用专业的分词工具。
            *   **技术选型**: 我们选用 ``jieba`` 库，它是目前社区最流行、效果最好的 Python 中文分词组件。
            *   **实现方式**: 清洗后的文本将被传递给 ``jieba.cut`` 方法，该方法会返回一个分词后的词语迭代器。这个过程将作为 ``TfidfVectorizer`` 的一部分，通过自定义 `tokenizer` 来实现。

        3.  **停用词过滤 (Stop Word Filtering)**: 文本中包含大量没有实际语义贡献的词语（如“的”、“是”、“在”等），这些词被称为停用词。过滤掉它们可以降低计算开销，并提高特征向量的质量。
            *   **实现方式**: 我们将维护一个自定义的中文停用词列表文件（例如 `stopwords.txt`）。在分词的同时，我们会检查每个词语是否在该停用词列表中，如果在，则将其舍弃。
            *   此步骤将与中文分词一同在自定义 `tokenizer` 中完成。

    * **最终输出**: 经过这三个步骤后，原始的文档内容切片将转换为一个由有意义的、干净的词语组成的列表（例如 `['项目', '目标', '用户', '文档', '整理']`），这个列表将作为 `TfidfVectorizer` 的最终输入。
